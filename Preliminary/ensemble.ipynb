{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mEPERM: operation not permitted, scandir '/Users/ThePokecrafter/Library/Messages/Attachments/74/04/D6CF7CFB-1133-445E-B0C1-33AB1E1DD65D'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "demographics_data = pd.read_csv(\"../Dataset/Demographics/demographics.csv\")\n",
    "sensing_data = pd.read_csv(\"../Dataset/Sensing/sensing.csv\")\n",
    "ema_data = pd.read_csv(\"../Dataset/EMA/general_ema.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, merge all three datasets into ONE DF\n",
    "def prepare_merged_dataset(sensing_data, demographics_data, ema_data):\n",
    "    \"\"\"\n",
    "    Merge sensing, demographics, and EMA data\n",
    "    \"\"\"\n",
    "    # Merge sensing and demographics first\n",
    "    merged = sensing_data.merge(\n",
    "        demographics_data,\n",
    "        on='uid',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Then merge with EMA data\n",
    "    merged = merged.merge(\n",
    "        ema_data,\n",
    "        on=['uid', 'day'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Add academic quarter\n",
    "    merged['quarter'] = merged['day'].apply(get_academic_quarter)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organized feature dictionary into categories and platforms\n",
    "''' \n",
    "Categories: demographics, activity, location, phone, sleep, audio, calls, sms, light, steps, quality\n",
    "Platforms: all, android, ios\n",
    "'''\n",
    "feature_dict = {\n",
    "    'demographics': [\n",
    "        'gender', 'race'\n",
    "    ],\n",
    "    \n",
    "    'activity': {\n",
    "        'all': [\n",
    "            'act_in_vehicle_ep_0', 'act_on_bike_ep_0', 'act_still_ep_0'\n",
    "        ],\n",
    "        'android': [\n",
    "            'act_on_foot_ep_0', 'act_tilting_ep_0'\n",
    "        ],\n",
    "        'ios': [\n",
    "            'act_running_ep_0', 'act_walking_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'location': [\n",
    "        'loc_dist_ep_0', 'loc_visit_num_ep_0', 'loc_max_dis_from_campus_ep_0',\n",
    "        'loc_food_dur', 'loc_health_dur', 'loc_home_dur', 'loc_leisure_dur',\n",
    "        'loc_other_dorm_dur', 'loc_self_dorm_dur', 'loc_social_dur', \n",
    "        'loc_study_dur', 'loc_workout_dur', 'loc_worship_dur'\n",
    "    ],\n",
    "    \n",
    "    'phone': {\n",
    "        'all': [\n",
    "            'unlock_duration_ep_0', 'unlock_num_ep_0'\n",
    "        ],\n",
    "        'ios': [\n",
    "            'other_playing_duration_ep_0', 'other_playing_num_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'sleep': {\n",
    "        'all': [\n",
    "            'sleep_duration', 'sleep_start', 'sleep_end'\n",
    "        ],\n",
    "        'ios': [\n",
    "            'sleep_heathkit_dur'\n",
    "        ]\n",
    "    },\n",
    "    'audio': {\n",
    "        'android': [\n",
    "            'audio_amp_mean_ep_0', 'audio_amp_std_ep_0',\n",
    "            'audio_convo_duration_ep_0', 'audio_convo_num_ep_0',\n",
    "            'audio_voice_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'calls': {\n",
    "        'android': [\n",
    "            'call_in_duration_ep_0', 'call_in_num_ep_0',\n",
    "            'call_out_duration_ep_0', 'call_out_num_ep_0',\n",
    "            'call_miss_num_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'sms': {\n",
    "        'android': [\n",
    "            'sms_in_num_ep_0', 'sms_out_num_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'light': {\n",
    "        'android': [\n",
    "            'light_mean_ep_0', 'light_std_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'steps': {\n",
    "        'ios': [\n",
    "            'step_ep_0'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'quality': {\n",
    "        'all': [\n",
    "            'quality_activity', 'quality_loc'\n",
    "        ],\n",
    "        'android': [\n",
    "            'quality_audio', 'quality_light'\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example feature dictionary (provided as feature_dict)\n",
    "# Define the merged dataset (replace with actual merged DataFrame)\n",
    "# merged_data = prepare_merged_dataset(sensing_data, demographics_data, ema_data)\n",
    "\n",
    "def select_features(platform, category_list):\n",
    "    \"\"\"\n",
    "    Select features based on platform and categories from feature_dict.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for category in category_list:\n",
    "        if isinstance(feature_dict[category], dict):  # Sub-dictionary for platform-specific features\n",
    "            if platform in feature_dict[category]:\n",
    "                features.extend(feature_dict[category][platform])\n",
    "            if 'all' in feature_dict[category]:  # Add cross-platform features\n",
    "                features.extend(feature_dict[category]['all'])\n",
    "        else:\n",
    "            features.extend(feature_dict[category])\n",
    "    return features\n",
    "\n",
    "def build_pipeline(merged_data, platform, categories, outcome, model_type=\"RandomForest\"):\n",
    "    \"\"\"\n",
    "    Builds a pipeline with customizable features and outcomes based on the platform and categories.\n",
    "    \n",
    "    Parameters:\n",
    "    - merged_data: the merged DataFrame with all features\n",
    "    - platform: platform-specific features to use ('all', 'android', 'ios')\n",
    "    - categories: list of categories to use (e.g., ['demographics', 'activity'])\n",
    "    - outcome: name of the target variable column\n",
    "    - model_type: ensemble model to use (\"RandomForest\", \"GradientBoosting\", \"AdaBoost\")\n",
    "    \n",
    "    Returns:\n",
    "    - A scikit-learn pipeline ready for training and evaluation\n",
    "    \"\"\"\n",
    "    features = select_features(platform, categories)\n",
    "    \n",
    "    X = merged_data[features]\n",
    "    y = merged_data[outcome]\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Choose the model\n",
    "    if model_type == \"RandomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model_type == \"GradientBoosting\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    elif model_type == \"AdaBoost\":\n",
    "        model = AdaBoostClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type. Choose 'RandomForest', 'GradientBoosting', or 'AdaBoost'.\")\n",
    "    \n",
    "    # Build the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_type} Model Accuracy: {accuracy:.2f}\")\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = prepare_merged_dataset(sensing_data, demographics_data, ema_data)\n",
    "\n",
    "categories = ['demographics', 'activity', 'location']\n",
    "platform = 'android'  # Specify platform compatibility\n",
    "outcome = 'target_variable'  # Replace with your actual outcome column\n",
    "\n",
    "# Train and evaluate the pipeline\n",
    "pipeline = build_pipeline(merged_data, platform, categories, outcome, model_type=\"RandomForest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
